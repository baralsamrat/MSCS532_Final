{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Naive Matrix Multiplication\n",
        "def naive_matrix_multiplication(A, B):\n",
        "    n = A.shape[0]\n",
        "    C = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            for k in range(n):\n",
        "                C[i][j] += A[i][k] * B[k][j]\n",
        "    return C\n",
        "\n",
        "# Blocked Matrix Multiplication\n",
        "def blocked_matrix_multiplication(A, B, block_size):\n",
        "    n = A.shape[0]\n",
        "    C = np.zeros((n, n))\n",
        "    for i in range(0, n, block_size):\n",
        "        for j in range(0, n, block_size):\n",
        "            for k in range(0, n, block_size):\n",
        "                # Multiply the sub-blocks\n",
        "                for ii in range(i, min(i + block_size, n)):\n",
        "                    for jj in range(j, min(j + block_size, n)):\n",
        "                        for kk in range(k, min(k + block_size, n)):\n",
        "                            C[ii][jj] += A[ii][kk] * B[kk][jj]\n",
        "    return C\n",
        "\n",
        "# Generate random matrices for testing\n",
        "n = 512  # Matrix size\n",
        "block_size = 64  # Block size for blocking optimization\n",
        "A = np.random.rand(n, n)\n",
        "B = np.random.rand(n, n)\n",
        "\n",
        "# Measure performance of naive multiplication\n",
        "start_time = time.time()\n",
        "C_naive = naive_matrix_multiplication(A, B)\n",
        "naive_time = time.time() - start_time\n",
        "print(f\"Naive Matrix Multiplication Time: {naive_time:.2f} seconds\")\n",
        "\n",
        "# Measure performance of blocked multiplication\n",
        "start_time = time.time()\n",
        "C_blocked = blocked_matrix_multiplication(A, B, block_size)\n",
        "blocked_time = time.time() - start_time\n",
        "print(f\"Blocked Matrix Multiplication Time: {blocked_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETJpV992nhxn",
        "outputId": "43ae7d8d-f288-4faf-9dd8-ff379c08028e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Matrix Multiplication Time: 178.02 seconds\n",
            "Blocked Matrix Multiplication Time: 152.52 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement HPC"
      ],
      "metadata": {
        "id": "RWjnkWpJo8yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from scipy.sparse import random as sparse_random\n",
        "from scipy.sparse.linalg import cg  # Conjugate Gradient solver\n",
        "\n",
        "# Set matrix dimensions and sparsity\n",
        "matrix_size = 1000  # You can scale this as needed\n",
        "density = 0.01  # Sparsity of the matrix\n",
        "\n",
        "# Generate a large random sparse matrix\n",
        "A = sparse_random(matrix_size, matrix_size, density=density, format='csr', dtype=np.float32)\n",
        "A = A @ A.T  # Make it symmetric positive-definite\n",
        "b = np.random.rand(matrix_size).astype(np.float32)  # Random vector for Ax = b\n",
        "\n",
        "# Solve with traditional PCG for comparison\n",
        "x_pcg, exit_code = cg(A, b)\n",
        "\n",
        "# 3. Neural Network-Based Surrogate Model\n",
        "# Define the neural network model using TensorFlow/Keras\n",
        "def build_surrogate_model(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.InputLayer(input_shape=input_shape),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(matrix_size)  # Output layer: approximate solution vector x\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Build the surrogate model\n",
        "input_shape = (matrix_size,)  # Each input vector b has size 'matrix_size'\n",
        "model = build_surrogate_model(input_shape)\n",
        "\n",
        "# 4. Generate training data\n",
        "def generate_training_data(num_samples):\n",
        "    b_vectors = []\n",
        "    x_solutions = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Generate synthetic data\n",
        "        A = sparse_random(matrix_size, matrix_size, density=density, format='csr', dtype=np.float32)\n",
        "        A = A @ A.T  # Make it symmetric positive-definite\n",
        "        b = np.random.rand(matrix_size).astype(np.float32)\n",
        "\n",
        "        # Solve using the PCG solver to get ground truth solution\n",
        "        x, _ = cg(A, b)  # Ground truth solution\n",
        "\n",
        "        b_vectors.append(b)  # Input to the model\n",
        "        x_solutions.append(x)  # Expected output (solution)\n",
        "\n",
        "    return np.array(b_vectors), np.array(x_solutions)\n",
        "\n",
        "# Generate training data\n",
        "num_samples = 1000\n",
        "b_train, x_train = generate_training_data(num_samples)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(b_train, x_train, epochs=50, batch_size=32)\n",
        "\n",
        "# 5. Evaluate Performance\n",
        "# Evaluate the surrogate model's performance\n",
        "def evaluate_surrogate_model(b):\n",
        "    # Use the surrogate model to predict the solution\n",
        "    x_pred = model.predict(b.reshape(1, -1))  # Reshape for batch prediction\n",
        "    return x_pred\n",
        "\n",
        "# Evaluate on a test matrix\n",
        "A_test = sparse_random(matrix_size, matrix_size, density=density, format='csr', dtype=np.float32)\n",
        "A_test = A_test @ A_test.T\n",
        "b_test = np.random.rand(matrix_size).astype(np.float32)\n",
        "\n",
        "# Traditional PCG solution\n",
        "x_pcg_test, _ = cg(A_test, b_test)\n",
        "\n",
        "# Surrogate model solution\n",
        "x_pred_test = evaluate_surrogate_model(b_test)\n",
        "\n",
        "# 6. Calculate and print performance improvement\n",
        "import time\n",
        "start_time_pcg = time.time()\n",
        "x_pcg_test, _ = cg(A_test, b_test)\n",
        "end_time_pcg = time.time()\n",
        "pcg_time = end_time_pcg - start_time_pcg\n",
        "\n",
        "start_time_surrogate = time.time()\n",
        "x_pred_test = evaluate_surrogate_model(b_test)\n",
        "end_time_surrogate = time.time()\n",
        "surrogate_time = end_time_surrogate - start_time_surrogate\n",
        "\n",
        "print(f\"PCG solver time: {pcg_time} seconds\")\n",
        "print(f\"Surrogate model time: {surrogate_time} seconds\")\n",
        "print(f\"Performance improvement: {pcg_time / surrogate_time}x\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkxACvbU0Et2",
        "outputId": "394c455f-1090-4221-f900-a96fa66ed73f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/linalg/_isolve/iterative.py:418: RuntimeWarning: overflow encountered in add\n",
            "  x += alpha*p\n",
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/linalg/_isolve/iterative.py:410: RuntimeWarning: overflow encountered in multiply\n",
            "  p *= beta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 2/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 3/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: nan\n",
            "Epoch 4/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 5/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 6/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: nan\n",
            "Epoch 7/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 8/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 9/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 10/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: nan\n",
            "Epoch 11/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: nan\n",
            "Epoch 12/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: nan\n",
            "Epoch 13/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 14/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 15/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 16/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: nan\n",
            "Epoch 17/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: nan\n",
            "Epoch 18/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 19/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: nan\n",
            "Epoch 20/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: nan\n",
            "Epoch 21/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 22/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 23/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 24/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 25/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 26/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 27/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 28/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 29/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: nan\n",
            "Epoch 30/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: nan\n",
            "Epoch 31/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: nan\n",
            "Epoch 32/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 33/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 34/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 35/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 36/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 37/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 38/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 39/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 40/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 41/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 42/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 43/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 44/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 45/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 46/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: nan\n",
            "Epoch 47/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: nan\n",
            "Epoch 48/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: nan\n",
            "Epoch 49/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: nan\n",
            "Epoch 50/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: nan\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "PCG solver time: 1.0920326709747314 seconds\n",
            "Surrogate model time: 0.08292293548583984 seconds\n",
            "Performance improvement: 13.169247622224011x\n"
          ]
        }
      ]
    }
  ]
}